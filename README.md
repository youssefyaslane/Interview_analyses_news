# FT Daily Pipeline â€” Config, DB & Scraper (Mongo + SeleniumBase)

Ce projet met en place un pipeline dâ€™analyse dâ€™articles FT (liens, contenus, analyses LLM). 

---

## ðŸ“‚ Arborescence (extrait)
```
Prject_analyse_news/
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ config.py                 # charge .env (Mongo URI, DB, noms de collections, UAâ€¦)
â”‚  â”œâ”€ Database/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â””â”€ db.py                 # connexion Mongo, index, upsert_link / upsert_article / upsert_analysis
â”‚  â”œâ”€ scraping/
â”‚  â”‚   â”œâ”€ scrape_links.py       # scraper SeleniumBase â†’ Mongo (ft_links)
â”‚  â”‚   â”œâ”€ fetch_articles_selenium.py  # scraper SeleniumBase â†’ Mongo (ft_articles)
â”‚  â”‚   â””â”€ utils.py              # utilitaires scraping (scroll, cookies, clean text)
â”‚  â””â”€ test/
â”‚     â”œâ”€ __init__.py
â”‚     â””â”€ test_db.py             # smoke test dâ€™insertion/lecture
â”œâ”€ requirements.txt
â”œâ”€ .env.example                 # gabarit des variables dâ€™env
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âš™ï¸ PrÃ©requis
- Python 3.10+
- MongoDB local ou Atlas (URI)
- Chrome/Chromium installÃ© (SeleniumBase sâ€™en sert)
- (optionnel) Profil Chrome avec extension chargÃ©e (voir plus bas)

---

## ðŸš€ Installation rapide (Windows PowerShell)
```
python -m venv venv
venv\Scripts\Activate.ps1
pip install -r requirements.txt
copy .env.example .env
```

Ajoute ensuite ce contenu dans **.env** :
```env
MONGODB_URI=mongodb://localhost:27017
MONGODB_DB=ft_daily
MONGODB_LINKS_COLLECTION=ft_links
MONGODB_ARTICLES_COLLECTION=ft_articles
MONGODB_ANALYSES_COLLECTION=ft_analyses

SCRAPER_USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36
GOOGLE_API_KEY=YOUR_API_KEY   # optionnel (pour la suite LLM)
```

---

## â–¶ï¸ Lancer les tests & scrapers

### 1. Tester la DB
```bash
python -m app.test.test_db
```

### 2. Lancer la DB
```bash
python -m app.Database.db
```
**Sortie attendue (exemple) :**
```
Links:     [ {...} ]
Articles:  [ {...} ]
Analyses:  [ {...} ]
```

### 3. Scraper les liens publics FT
```bash
python -m app.scraping.scrape_links
```
Exemple de sortie :
```
=== https://www.ft.com/ ===
[INFO] https://www.ft.com/ -> 30 liens trouvÃ©s
[OK] 30 liens upsertÃ©s pour https://www.ft.com/
...
âœ… TerminÃ©. Total liens upsertÃ©s: 121
```

Les liens sont insÃ©rÃ©s/mis Ã  jour dans la collection **ft_links** de MongoDB.

---

## ðŸ§© Utiliser Chrome avec extension

tÃ©lÃ©chargement dâ€™extensions de contournement de paywall **profil Chrome avec extension** :

1. TÃ©lÃ©charge ton dossier d'aprÃ¨s ce lien "https://gitflic.ru/project/magnolia1234/bypass-paywalls-chrome-clean#installation".
2. Ouvre Chrome â†’ `chrome://extensions/`.
3. Active **Mode dÃ©veloppeur** (coin supÃ©rieur droit).
4. Clique sur **Charger lâ€™extension non empaquetÃ©e**.
5. poser ton dossier.
6. Mets Ã  jour `fetch_articles_selenium.py` pour rÃ©utiliser ton profil :
   ```python
   profile_dir = r"C:\Users\HP\AppData\Local\Google\Chrome\User Data\Default"
   fetch_articles_from_mongo(limit_per_run=None, headless=False, profile_dir=profile_dir)
   ```

---

### 4. Scraper les articles complets FT
```bash
python -m app.scraping.fetch_articles_selenium
```

### Collection `ft_links`
```json
{
  "title": "US to take 10% stake in troubled chipmaker Intel",
  "url": "https://www.ft.com/content/Id_article",
  "section": "home",
  "source": "listing",
  "first_seen": "2025-08-25T10:44:29Z",
  "last_seen": "2025-08-25T10:44:29Z"
}
```

### Collection `ft_articles`
```json
{
  "url": "https://www.ft.com/content/Id_article",
  "title": "US to take 10% stake in troubled chipmaker Intel",
  "body_article": "Texte complet de lâ€™article...",
  "word_count": 1432,
  "fetched_at": "2025-08-27T11:12:00Z"
}
```

---

## ðŸ“Œ Roadmap
1. âœ… Step 1 : Config + DB helpers  
2. âœ… Step 2 : Scraper liens publics â†’ `ft_links`  
3. âœ… Step 3 : Fetch articles complets â†’ `ft_articles`  
4. ðŸ”œ Step 4 : Analyse LLM (Gemini) â†’ `ft_analyses`  
5. ðŸ”œ Step 5 : Orchestration Airflow (1 exÃ©cution/jour)  
6. ðŸ”œ Step 6 : Dashboard (Metabase / PowerBI)

---
## âœ¨ Auteur
**Youssef Yaslane** â€” *Data Scientist | Big Data & IA Engineer*
